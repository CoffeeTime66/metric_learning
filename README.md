# Next Generation Loss (NGL)

На основе информации, представленной в [данной статье](https://arxiv.org/html/2404.12948v1), ниже представлен обзор функции NGL (Потери следующего поколения):

Функция NGL была обнаружена с помощью эволюционного метода с использованием генетического программирования (GP) для поиска функции потерь, которая могла бы превзойти стандартную потерю перекрестной энтропии (CE) в различных наборах данных классификации изображений. Авторы указывают на то, что функция NGL была единственной из 5 найденных лучших функций, которая показала значительно лучшие результаты, чем CE в среднем по протестированным наборам данных.

## Формула функции NGL:

*fNGL = 1/N * Σ(e^(α - y_pred * (1 + y_real)) - cos(cos(sin(y_pred))))*

Где:
- N - количество классов
- α = 2,4092
- y_pred — прогнозируемый результат после применения функции softmax
- y_real — настоящий лейбл

## Ключевые характеристики функции NGL:

1. Она превосходила стандартную функцию потерь CE, а также другие функции потерь, такие как симметричная перекрестная энтропия (SCE) и фокусная потеря, на различных наборах данных, включая Malaria, CIFAR-10, Fashion-MNIST и особенно набор данных PCam.

2. Он показал улучшенную точность топ-1 по сравнению с моделями, обученными с помощью CE, SCE и Focal Loss в крупномасштабном наборе данных ImageNet-1k при использовании с моделями ResNet и Swin Transformer.

3. Функция NGL также применялась к задачам сегментации наборов данных Pascal VOC 2012 и COCO-Stuff164k, где она улучшила производительность базовых моделей U-Net и DeepLab.

4. Авторы предполагают, что функция NGL обладает свойством саморегуляризации, что может быть причиной ее высокой производительности в различных наборах данных и задачах.

5. Хотя функция NGL была обнаружена экспериментально без теоретической поддержки, авторы указывают на то, что она представляет собой многообещающее направление для разработки эффективных функций потерь для глубокого обучения, особенно для задач классификации и сегментации.

### Однако в связи с ограничениями по времени (поздно взялся за задание) на датасете Humpback Whale удалось достичь точности только в 0.36-0.37, потери же держались на уровне ~5
![image](https://github.com/CoffeeTime66/metric_learning/assets/42956546/7c3ccffd-6db9-488f-a13e-eb79838dfc21)

что судя по [графикам](https://github.com/ZKI-PH-ImageAnalysis/Next-Generation-Loss/tree/main) является нормальным 
